import json
import uuid
import os

# è¿™ä¸ªè„šæœ¬ç”¨äºç”Ÿæˆ V7 "All-in-One" å·¥ä½œæµ
# å®ƒä¼šåŸºäº V6 çš„ç»“æ„ï¼Œä½†å¤§å¹…ç²¾ç®€èŠ‚ç‚¹ï¼Œå› ä¸ºå¤§éƒ¨åˆ†è®¡ç®—éƒ½ç§»åˆ°äº† Python API

INPUT_FILE = "AH_Stock_V6_Cloud.json" # åŸºäº V6 ç»§ç»­ä¿®æ”¹
OUTPUT_FILE = "AH_Stock_V7_FullStack.json"

# ç”¨æˆ·éƒ¨ç½²çš„ API åœ°å€ (å ä½ç¬¦)
DEMO_API_URL = "http://replace-with-your-cloud-run-url.com"

# === New V7 Nodes ===

def create_full_analysis_node():
    # è°ƒç”¨ V7 çš„ /analyze_full æ¥å£
    return {
        "parameters": {
            "url": f"{DEMO_API_URL}/analyze_full",
            "method": "POST",
            "authentication": "none",
            "sendBody": True,
            "contentType": "json",
            "bodyParameters": {
                "parameters": [
                    {"name": "code", "value": "={{ $json.code }}"},
                    {"name": "balance", "value": 100000},
                    {"name": "risk", "value": 0.01}
                ]
            },
            "options": {}
        },
        "id": str(uuid.uuid4()),
        "name": "Full Stack Analysis (API)",
        "type": "n8n-nodes-base.httpRequest",
        "typeVersion": 4.1,
        "position": [-1850, 450],
        "retryOnFail": True,
        "maxTries": 3,
        "waitBetweenTries": 3000
    }

# V7 éœ€è¦ä¸€ä¸ªæ–°çš„ AI Prompt èŠ‚ç‚¹é€»è¾‘ï¼Œå› ä¸ºè¾“å…¥æ•°æ®ç»“æ„å˜äº†
def update_ai_prompt_code(node):
    # ä»¥å‰æ˜¯æ‹¼æ¥ raw stringï¼Œç°åœ¨ API å·²ç»å¸®æˆ‘ä»¬æŠŠ key info æ‹¼å¥½äº†
    # æˆ‘ä»¬åªéœ€è¦ç®€å•ç»„åˆä¸€ä¸‹
    new_code = r"""
const data = $json;
const tech = data.technical;
const sig = data.signal;
const risk = data.risk_ctrl;
const marketStatus = $('Global Context (API)').item.json.market_status;

// è·å–æ–°é—»æ•°æ® (Tavily èŠ‚ç‚¹åœ¨å‰é¢)
// æ³¨æ„ï¼šV7 æµç¨‹æœ‰å˜ï¼Œæˆ‘ä»¬å‡è®¾ Tavily èŠ‚ç‚¹è¿˜åœ¨ Analysis ä¹‹å
let news_text = "æœªæœç´¢åˆ°æ–°é—»";
try {
    const news = $('Tavilyæ–°é—»æœç´¢').item.json;
    if (news.results) {
        news_text = news.results.map(r => `- ${r.title}`).join('\n');
    } else if (news.answer) {
        news_text = news.answer;
    }
} catch(e) {}

const prompt = `# å†³ç­–ä»ªè¡¨ç›˜åˆ†æè¯·æ±‚

## è‚¡ç¥¨åŸºç¡€
- ä»£ç : ${data.code} (${data.market})
- å¤§ç›˜ç¯å¢ƒ: ${marketStatus}
- ç°ä»·: ${tech.current_price}

## ä¿¡å·ç³»ç»Ÿ (V7.1 Hybrid)
- æ ¸å¿ƒä¿¡å·: ${sig.signal}
- è¶‹åŠ¿è¯„åˆ†: ${sig.trend_score}/100
- ç†ç”±: ${sig.signal_reasons.join(', ') || 'æ— '}

## é£æ§å‚æ•°
- æ­¢æŸä»·: ${sig.stop_loss}
- ç›®æ ‡ä»·: ${sig.take_profit}
- ATRæ³¢åŠ¨: ${tech.atr14}
- å»ºè®®ä»“ä½: ${risk.suggested_position} æ‰‹ (åŸºäº1%é£é™©)

## æŠ€æœ¯æŒ‡æ ‡
- MAæ’åˆ—: ${tech.ma_alignment} (${tech.ma5}/${tech.ma20})
- EMAè¶‹åŠ¿: 13æ—¥çº¿ ${tech.ema13} vs 26æ—¥çº¿ ${tech.ema26}
- ä¹–ç¦»ç‡: ${tech.bias_ma5}%
- RSI(14): ${tech.rsi14}
- é‡æ¯”: ${tech.volume_ratio}

## æ–°é—»æ‘˜è¦
${news_text}

è¯·åŸºäºä»¥ä¸Šæ•°æ®ï¼Œç”¨ç®€ç»ƒçš„ä¸“ä¸šæœ¯è¯­ç”Ÿæˆäº¤æ˜“è®¡åˆ’ã€‚

// --- åŠ¨æ€é£é™©æç¤ºé€»è¾‘ ---
let risk_instruction = "";
if (marketStatus === 'Bear' || marketStatus === 'Crash') {
    risk_instruction = `
!!! ğŸ”´ ä¸¥é‡è­¦å‘Šï¼šå½“å‰å¤„äºç†Šå¸‚/æš´è·Œç¯å¢ƒ (${marketStatus}) !!!
1. **ä¸¥æ ¼æ ‡å‡†**ï¼šä»…å…è®¸è¯„åˆ†>85ä¸”æœ‰é‡å¤§åˆ©å¥½çš„ä¸ªè‚¡æ“ä½œã€‚
2. **å¼ºåˆ¶è½»ä»“**ï¼šå»ºè®®ä»“ä½å¿…é¡»å‡åŠï¼Œæˆ–è€…ç›´æ¥å»ºè®®ç©ºä»“ã€‚
3. **å¯»æ‰¾åšç©ºæœºä¼š**ï¼šå¦‚æœæ˜¯æ¸¯è‚¡ï¼Œä¼˜å…ˆå¯»æ‰¾åšç©ºé€»è¾‘ï¼›å¦‚æœæ˜¯Aè‚¡ï¼Œå»ºè®®ä»¥â€œè§‚æœ›â€ä¸ºä¸»ã€‚
4. **æªè¾ä¸¥å‰**ï¼šè¯·åœ¨æ ¸å¿ƒç»“è®ºä¸­ç”¨ç²—ä½“å¼ºè°ƒå¤§ç›˜é£é™©ã€‚`;
}

const final_prompt = prompt + risk_instruction;

return {
    json: {
        prompt: final_prompt,
        raw_data: data
    }
};
"""
    node['parameters']['jsCode'] = new_code
    return node

# === Main Build Logic ===

if not os.path.exists(INPUT_FILE):
    print(f"Error: {INPUT_FILE} not found.")
    exit(1)

with open(INPUT_FILE, 'r', encoding='utf-8') as f:
    workflow = json.load(f)

nodes = workflow.get('nodes', [])
connections = workflow.get('connections', {})

# 1. ç§»é™¤æ—§çš„å¤æ‚èŠ‚ç‚¹
# æˆ‘ä»¬éœ€è¦ç§»é™¤: "è®¡ç®—Aè‚¡æŠ€æœ¯æŒ‡æ ‡", "è®¡ç®—æ¸¯è‚¡æŠ€æœ¯æŒ‡æ ‡", "åˆå¹¶æŠ€æœ¯æŒ‡æ ‡", "Stock Risk Analysis (API)", "Merge Analysis Data"
# ä¿ç•™: Trigger, Global Context, Filter, Read List, Tavily, AI Prompt, Parse AI, Feishu

nodes_to_remove = [
    "è®¡ç®—Aè‚¡æŠ€æœ¯æŒ‡æ ‡", "è®¡ç®—æ¸¯è‚¡æŠ€æœ¯æŒ‡æ ‡", "åˆå¹¶æŠ€æœ¯æŒ‡æ ‡", 
    "Stock Risk Analysis (API)", "Stock Risk Analysis", # V6 Name
    "Merge Analysis Data",
    "åˆ¤æ–­å¸‚åœºç±»å‹", "è…¾è®¯è´¢ç»_å®æ—¶è¡Œæƒ…", "YahooFinance_æ¸¯è‚¡æ•°æ®",
    "è§£æè…¾è®¯æ•°æ®", "è§£æYahooæ•°æ®", "è…¾è®¯è´¢ç»_Kçº¿æ•°æ®",
    "Market Regime Filter" # User requested to bypass this circuit breaker
]

workflow['nodes'] = [n for n in nodes if n['name'] not in nodes_to_remove]
nodes = workflow['nodes'] # Update ref

# 2. æ’å…¥ "Full Stack Analysis (API)"
analysis_node = create_full_analysis_node()
workflow['nodes'].append(analysis_node)

# 3. é‡è¿é€»è¾‘
# æµç¨‹: Trigger -> Global Context -> Read List -> SplitBatch -> Analysis...

trigger = next(n for n in nodes if n['name'] == 'å®šæ—¶è§¦å‘_å·¥ä½œæ—¥18ç‚¹')
global_ctx = next(n for n in nodes if n['name'] == 'Global Context (API)')
read_list = next(n for n in nodes if n['name'] == 'è¯»å–è‚¡ç¥¨åˆ—è¡¨')
split_node = next(n for n in nodes if n['name'] == 'å¾ªç¯å¤„ç†æ¯åªè‚¡ç¥¨')
tavily = next(n for n in nodes if n['name'] == 'Tavilyæ–°é—»æœç´¢')
prompt_node = next(n for n in nodes if n['name'] == 'æ„å»ºAIæç¤ºè¯')

# Connect Trigger -> Global Context
connections[trigger['name']] = {"main": [[
    {"node": global_ctx['name'], "type": "main", "index": 0}
]]}

# Connect Global Context -> Read List (Bypassing Filter)
connections[global_ctx['name']] = {"main": [[
    {"node": read_list['name'], "type": "main", "index": 0}
]]}

# Connect Read List -> SplitBatch
connections[read_list['name']] = {"main": [[
    {"node": split_node['name'], "type": "main", "index": 0}
]]}
# Connect SplitBatch -> Full Stack Analysis
# Note: SplitInBatches has 2 outputs (Loop, Done). We connect Loop (index 0).
connections[split_node['name']] = {"main": [
    [{"node": analysis_node['name'], "type": "main", "index": 0}], # Output 0: Loop
    [] # Output 1: Done
]}

connections[analysis_node['name']] = {"main": [[
    {"node": tavily['name'], "type": "main", "index": 0}
]]}

# Tavily -> AI Prompt (Existing connection usually fine, but let's ensure)
connections[tavily['name']] = {"main": [[
    {"node": prompt_node['name'], "type": "main", "index": 0}
]]}

# 4. æ›´æ–° AI Prompt èŠ‚ç‚¹ä»£ç 
prompt_node = update_ai_prompt_code(prompt_node)

# 5. æ›´æ–°å†™å…¥é£ä¹¦
feishu = next(n for n in nodes if n['name'] == 'å†™å…¥é£ä¹¦')
# V7 API è¿”å›ç»“æ„å˜äº†ï¼Œæˆ‘ä»¬éœ€è¦é€‚é…
# $json.risk_ctrl.suggested_position
# $json.signal.signal
# $json.technical.atr14
# ä»¥å‰çš„æ•°æ®éƒ½åœ¨æ ¹èŠ‚ç‚¹æˆ–è€…æ··ä¹±åˆ†å¸ƒï¼Œç°åœ¨å¾ˆç»“æ„åŒ–

v7_body = r'''={{
JSON.stringify({
  "records": [
    {
      "fields": {
        "æ—¥æœŸ": new Date().getTime(),
        "ä»£ç ": $('Full Stack Analysis (API)').item.json.code,
        "åç§°": $('Full Stack Analysis (API)').item.json.name,
        "å¤§ç›˜çŠ¶æ€": $('Global Context (API)').item.json.market_status,
        
        "ä¿¡å·ç±»å‹": $('Full Stack Analysis (API)').item.json.signal.signal,
        "æ“ä½œå»ºè®®": $json.operation_advice, 
        "æ ¸å¿ƒç»“è®º": $json.one_sentence,
        
        "å»ºè®®ä»“ä½(æ‰‹)": $('Full Stack Analysis (API)').item.json.risk_ctrl.suggested_position,
        "æ­¢æŸä»·": $('Full Stack Analysis (API)').item.json.signal.stop_loss,
        "ATR": $('Full Stack Analysis (API)').item.json.technical.atr14,
        "RSI": $('Full Stack Analysis (API)').item.json.technical.rsi14,
        "é‡æ¯”": $('Full Stack Analysis (API)').item.json.technical.volume_ratio,
        "å‡çº¿å½¢æ€": $('Full Stack Analysis (API)').item.json.technical.ma_alignment,
        
        "é£é™©è­¦æŠ¥": $json.risk_alerts,
        "æ£€æŸ¥æ¸…å•": $json.checklist
      }
    }
  ]
})
}}'''

feishu['parameters']['body'] = v7_body

# Clean up connections dictionary (remove dead keys)
valid_node_names = [n['name'] for n in nodes]
clean_connections = {}
for source, conns in connections.items():
    if source in valid_node_names:
        clean_connections[source] = conns
workflow['connections'] = clean_connections

# Save
with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
    json.dump(workflow, f, indent=2, ensure_ascii=False)

print(f"Success! Generated {OUTPUT_FILE}")
print("Workflow Simplified: Removed legacy JS calculation nodes.")
print("Connected: Read List -> Full Analysis API -> Tavily")
